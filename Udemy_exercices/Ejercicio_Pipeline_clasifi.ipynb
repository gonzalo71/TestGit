{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda69e58c37ea7d4cdf93b91f6c517dcb7c",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Ejercicio elegir pipeline en clasficacion\n",
    "https://towardsdatascience.com/simple-way-to-find-a-suitable-algorithm-for-your-data-in-scikit-learn-python-9a9710c7c0fe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "891 rows, 9 columns\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   survived     sex   age  sibsp  parch     fare  class deck  embark_town\n",
       "0         0    male  22.0      1      0   7.2500  Third  NaN  Southampton\n",
       "1         1  female  38.0      1      0  71.2833  First    C    Cherbourg\n",
       "2         1  female  26.0      0      0   7.9250  Third  NaN  Southampton\n",
       "3         1  female  35.0      1      0  53.1000  First    C  Southampton\n",
       "4         0    male  35.0      0      0   8.0500  Third  NaN  Southampton"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>deck</th>\n      <th>embark_town</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Southampton</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>Third</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Set seed\n",
    "seed = 8\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seaborn import load_dataset\n",
    "\n",
    "# Machine learning pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Import data\n",
    "exclude = ['pclass', 'embarked', 'who', 'adult_male', 'alive', 'alone']\n",
    "df = load_dataset('titanic').drop(columns=exclude)\n",
    "\n",
    "# Inspect shape of the data and top rows\n",
    "print(f\"{df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data (712 rows): Target distribution\n0    0.616573\n1    0.383427\nName: survived, dtype: float64\n\nTest data (179 rows): Target distribution\n0    0.616573\n1    0.383427\nName: survived, dtype: float64\n\nNumerical: Index(['age', 'sibsp', 'parch', 'fare'], dtype='object')\nCategorical: Index(['class', 'deck', 'embark_town', 'sex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Set target\n",
    "target = 'survived'\n",
    "features = df.drop(columns=target).columns\n",
    "\n",
    "# Split data into train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], \n",
    "                                                    test_size=.2, random_state=seed, \n",
    "                                                    stratify=df[target])\n",
    "\n",
    "# Inspect data\n",
    "print(f\"Training data ({X_train.shape[0]} rows): Target distribution\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nTest data ({X_test.shape[0]} rows): Target distribution\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Define feature groups\n",
    "numerical = X_train.select_dtypes(['number']).columns\n",
    "print(f'\\nNumerical: {numerical}')\n",
    "categorical = X_train.columns.difference(numerical)\n",
    "X_train[categorical] = X_train[categorical].astype('object')\n",
    "print(f'Categorical: {categorical}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"A custom transformer that imputes with a constant value in place.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    value: (optional) A value to impute with\n",
    "    \"\"\"\n",
    "    def __init__(self, value='missing'):\n",
    "        self.value = value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X.fillna(self.value, inplace=True)\n",
    "        return X\n",
    "    \n",
    "class CardinalityReducer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"A custom transformer that encodes infrequent labels into 'other' in place.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold: (optional) An integer for minimum threshold frequency count or \n",
    "    a float for threshold of frequency proportion to keep the category. If \n",
    "    category frequency doesn't surpass the threshold, its value will be \n",
    "    overwritten with 'other'.  \n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=.01):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.top_categories = {}\n",
    "        for feature in X.columns:\n",
    "            frequencies = pd.Series(X[feature].value_counts(normalize=True))\n",
    "            if isinstance(self.threshold, int):\n",
    "                top_categories = frequencies.head(self.threshold).index\n",
    "            elif isinstance(self.threshold, float):   \n",
    "                top_categories = frequencies[frequencies>self.threshold].index\n",
    "            self.top_categories[feature] = list(top_categories)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for feature in X.columns:\n",
    "            X[feature] = np.where(X[feature].isin(self.top_categories[feature]), \n",
    "                                  X[feature], 'other')\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   class_First  class_Second  class_Third  deck_A  deck_B  deck_C  deck_D  \\\n",
       "0          0.0           0.0          1.0     0.0     0.0     0.0     0.0   \n",
       "1          0.0           0.0          1.0     0.0     0.0     0.0     0.0   \n",
       "2          0.0           0.0          1.0     0.0     0.0     0.0     0.0   \n",
       "3          0.0           0.0          1.0     0.0     0.0     0.0     0.0   \n",
       "4          0.0           0.0          1.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   deck_E  deck_F  deck_missing  ...  embark_town_Cherbourg  \\\n",
       "0     0.0     0.0           1.0  ...                    0.0   \n",
       "1     0.0     0.0           1.0  ...                    0.0   \n",
       "2     0.0     0.0           1.0  ...                    0.0   \n",
       "3     0.0     0.0           1.0  ...                    0.0   \n",
       "4     0.0     0.0           1.0  ...                    0.0   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  embark_town_other  \\\n",
       "0                     0.0                      1.0                0.0   \n",
       "1                     1.0                      0.0                0.0   \n",
       "2                     0.0                      1.0                0.0   \n",
       "3                     0.0                      1.0                0.0   \n",
       "4                     0.0                      1.0                0.0   \n",
       "\n",
       "   sex_female  sex_male       age  sibsp  parch      fare  \n",
       "0         0.0       1.0  0.258608  0.000    0.0  0.031425  \n",
       "1         0.0       1.0  0.363052  0.000    0.0  0.013565  \n",
       "2         0.0       1.0  0.258608  0.000    0.0  0.016461  \n",
       "3         0.0       1.0  0.363052  0.000    0.0  0.015835  \n",
       "4         1.0       0.0  0.220910  0.125    0.0  0.034743  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_First</th>\n      <th>class_Second</th>\n      <th>class_Third</th>\n      <th>deck_A</th>\n      <th>deck_B</th>\n      <th>deck_C</th>\n      <th>deck_D</th>\n      <th>deck_E</th>\n      <th>deck_F</th>\n      <th>deck_missing</th>\n      <th>...</th>\n      <th>embark_town_Cherbourg</th>\n      <th>embark_town_Queenstown</th>\n      <th>embark_town_Southampton</th>\n      <th>embark_town_other</th>\n      <th>sex_female</th>\n      <th>sex_male</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.258608</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.031425</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.363052</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.013565</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.258608</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.016461</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.363052</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.015835</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.220910</td>\n      <td>0.125</td>\n      <td>0.0</td>\n      <td>0.034743</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Build preprocessing pipeline\n",
    "categorical_pipe = Pipeline([('imputer', Imputer()),\n",
    "                             ('cardinality_reducer', CardinalityReducer()),\n",
    "                             ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "numerical_pipe = Pipeline([('imputer', SimpleImputer(strategy='mean')),\n",
    "                           ('scaler', MinMaxScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', categorical_pipe, categorical),\n",
    "                                               ('num', numerical_pipe, numerical)])\n",
    "# Fit and transform training data\n",
    "preprocessor.fit(X_train)\n",
    "cat = preprocessor.named_transformers_['cat']['encoder'].get_feature_names(categorical)\n",
    "columns = np.append(cat, numerical)\n",
    "X_train_transformed = pd.DataFrame(preprocessor.transform(X_train), columns=columns)\n",
    "X_train_transformed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}